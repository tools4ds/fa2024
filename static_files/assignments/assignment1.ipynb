{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Introduction to Pandas and Scikit-Learn\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python. It provides data structures like DataFrames and Series that allow for efficient handling of structured data. Pandas is particularly useful for tasks such as reading and writing data in various formats, data cleaning, merging datasets, and performing complex operations on data.\n",
    "\n",
    "Scikit-learn, on the other hand, is a machine learning library for Python. It provides a wide range of supervised and unsupervised learning algorithms, as well as tools for model selection, evaluation, and preprocessing. Scikit-learn is designed to be user-friendly and efficient, making it a popular choice for both beginners and experienced data scientists.\n",
    "\n",
    "Together, Pandas and Scikit-learn form a powerful combination for data analysis and machine learning tasks. Pandas is often used to prepare and manipulate data, which can then be fed into Scikit-learn models for training and prediction.\n",
    "\n",
    "In this assignment, we'll start with the fundamentals of data loading/manipulatin in pandas, then move on to basics of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick look at the dataset. We'll use the .head() function to view the first 5 records of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Feel free to refer to the course notes on [pandas](https://tools4ds.github.io/DS701-Course-Notes/02B-Pandas.html) for the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1a**: Write a function `get_rows_and_columns` that takes as input a CSV filename, loads this file into a Pandas dataframe, and returns a tuple of the number of rows and columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rows_and_columns(file_path):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 1b**: Write a function `compute_missing_percentage` that converts '?' to NaN and returns the percentage of missing data (i.e., NaNs) for each column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_missing_percentage(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1c**: Write a function `unique_ms` that returns the number of unique marital-statuses present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unique_ms(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1d**: Write a function `get_categorical_columns` that identifies and returns a list of all the **categorical** columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_categorical_columns(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 2: Exploratory data analysis and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2a**: Write a function `plot_categorical_distribution` to plot the distribution of the column 'relationship'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_categorical_distribution(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2b**: Write a function `plot_age_hours_scatter` that creates a scatter plot of 'age' vs 'hours-per-week', coloring points by 'income'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_age_hours_scatter(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2c**: Write a function `plot_income_by_education` which plots a stacked bar chart that shows the proportion of income levels for each 'education' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_income_by_education(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Part 3: Advanced Pandas Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3a**: Write a function `education_stats` that returns a dataframe with mean 'age' and median 'hours-per-week' categorized on the 'education' level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def education_stats(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3b**: Write a function `calculate_high_income_percentage` that returns a dataframe of the percentage of individuals earning >50K for each 'native-country' and order them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_high_income_percentage(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3c**: Write a function `occupations_by_hours` that returns a dataframe of the top 5 occupations with the higheset average 'hours-per-week'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_5_occupations_by_hours(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO RUN THIS CELL!\n",
    "\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "df_new = df.drop(columns=['native-country', 'fnlwgt']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll implement [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) using scikit-learn. Logistic regression is used when trying to predict a binary outcome (0 or 1, True or False, etc.) We will go over the details of logistic regression in details later in the course. \n",
    "\n",
    "Here, we will try to predict income (>50k or <= 50k>) and follow standard ML procedures for data pre-processing. You can use scikit-learn's documentation, [the lecture notes on scikit-learn](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html) or online resources for guidance. \n",
    "\n",
    "#### From here on use the 'df_new' variable instead of 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We saw in lecture that models are trained on the 'training' set and evaluated on unseen data on the 'testing' set. The dataset has 'feature' (`X_train`, `X_test`) and the 'outcome' (`y_train`, `y_test`) variables. \n",
    "\n",
    "**Question 4a:** Write a function called `split_data` that takes a dataframe as its only parameter, splits it into training and test splits and returns them. Use 20% for the testing set. \n",
    "\n",
    "Use `train_test_split` to produce the splits. Provide a `random_state` of 42 for reproducibility.\n",
    "\n",
    "`split_data` should return 4 things: X_train, X_test y_train and y_test. To do that, you need to pass in the X *and* the y (income column) to `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 4b**: Write a function `preprocess_data` that takes X_train, y_train, X_test, and y_test as input (the splits we created earlier!) and does the following:\n",
    "\n",
    " - Scale the *numerical* columns using sklearn's `MinMaxScaler` to the range [0,1] for both train and test sets\n",
    "  \n",
    " - Replace \"<=50K\" with 0 and \">50K\" with 1 in both y_train and y_test\n",
    "\n",
    " - One-hot encode the categorical columns for both train and test sets. Check the next cell for some hints! \n",
    "  \n",
    "The function should then return the preprocessed X_train, y_train, X_test, and y_test\n",
    "\n",
    "Refer to the material below and [sklearn course notes](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html#prepare-the-dataset) for help! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One hot encoding is a way of turning textual data into numbers, so that models can work with them. \n",
    "\n",
    "Pandas has a method called `pd.get_dummies()` that can do one-hot encoding. Here's an example usage: \n",
    "  \n",
    "   ```python\n",
    "    # Sample DataFrame with categorical columns\n",
    "    data = {'City': ['New York', 'Los Angeles', 'New York', 'Chicago'],\n",
    "        'Gender': ['Female', 'Male', 'Male', 'Female']}\n",
    "\n",
    "    df = pd.DataFrame(data) \n",
    "\n",
    "    df_encoded = pd.get_dummies(df, columns=['City', 'Gender']) # notice how I'm passing in the columns -- you should do this too! Hint: you wrote a function for this earlier. \n",
    "   ```\n",
    "   \n",
    "   And then `df_encoded` will look like: \n",
    "\n",
    "   ```python\n",
    "      City_Chicago  City_Los Angeles  City_New York  Gender_Female  Gender_Male\n",
    "    0             0                 0              1              1            0\n",
    "    1             0                 1              0              0            1\n",
    "    2             0                 0              1              0            1\n",
    "    3             1                 0              0              1            0\n",
    "   ```\n",
    "\n",
    "   Notice how now every `City` value has its own column, and that every row with a city has a 1 for that city (row 1 in the old dataframe has New York for the `City`, and row in the new dataframe has a 1 for `City_New York`). Everywhere else you have a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's get to training! Remember, we're trying to predict whether income is more then 50k (>50k), or less than or equal to (<=50k).\n",
    "\n",
    "**Question 4c:** Write a function called train_model that takes the training splits (X_train and y_train) as its parameters. \n",
    "\n",
    "- Initialize the logistic regression model\n",
    "- Fit it to our data. (Training step)\n",
    "\n",
    "At the end, return the fitted model. \n",
    "\n",
    "You can refer to [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's evaluate the performance of our model! \n",
    "\n",
    "**Question 4d:** Write a function called evaluate_model that takes the fitted model and `X_test`, `y_test` as parameters, runs the model on the testing features (`X_test`) and returns the *accuracy score* of the predictions against the ground truth (`y_test`). \n",
    "\n",
    "You can refer to [sklearn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Submit the notebook after completing all the questions to Gradescope to view your results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> get_rows_and_columns('adult.csv') == (48842, 15)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> get_rows_and_columns('adult.csv') == (4, 15)\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> unique_ms(df) == 7\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_ms(df) == 6\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> get_categorical_columns(df) == ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> get_categorical_columns(df) == ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(education_stats(df)) == 16\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(education_stats(df).columns) == {'education', 'age', 'hours-per-week'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(education_stats(df).iloc[0]['age'], 37.902808))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(education_stats(df).iloc[1]['hours-per-week'] == 40.0)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> int(education_stats(df)['hours-per-week'].value_counts().get(40.0, 0)) == 14\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> education_stats(df).iloc[13]['education'] == 'Preschool'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> education_stats(df).iloc[7]['education'] == 'Assoc-acdm'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(calculate_high_income_percentage(df)['France'], 42.10526315789473))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(calculate_high_income_percentage(df)['India'], 41.059603))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(calculate_high_income_percentage(df)['China'], 29.508197))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(top_5_occupations_by_hours(df)['Farming-fishing'], 46.81744966442953))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(top_5_occupations_by_hours(df)['Exec-managerial'], 44.975353))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(top_5_occupations_by_hours(df)['Prof-specialty'], 42))\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_split_data():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     output = split_data(df_new)\n...     assert len(output) == 4, 'split_data() should return 4 things. Make sure you pass both the X and the y to train_test_split.'\n...     X_train, X_test, y_train, y_test = output\n...     assert len(X_train) + len(X_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert len(y_train) + len(y_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert np.all(X_train.columns == X_test.columns), 'The columns in X_train and X_test are not the same.'\n...     assert len(X_train) > 0 and len(X_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n...     assert len(y_train) > 0 and len(y_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n>>> test_split_data()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_correct_X():\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         X_train, X_test, y_train, y_test = split_data(df_new)\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(X_train.columns == X_test.columns), 'The columns in X_train and X_test are not the same.'\n...     assert np.allclose(np.mean(X_train), np.mean(X_test), atol=0.01), 'The mean of every column is not the same in X_train and X_test.'\n...     assert np.all((X_train >= 0) & (X_train <= 1)), 'X_train has values that are not between 0 and 1.'\n...     assert np.all((X_test >= 0) & (X_test <= 1)), 'X_test has values that are not between 0 and 1.'\n...     assert np.all((np.mean(X_train) >= 0) & (np.mean(X_train) <= 1)), 'X_train has columns with mean values not between 0 and 1.'\n...     assert np.all((np.mean(X_test) >= 0) & (np.mean(X_test) <= 1)), 'X_test has columns with mean values not between 0 and 1.'\n>>> \n>>> def test_correct_y():\n...     splits = train_test_split(df_new.drop(columns='income'), df_new['income'], test_size=0.2, random_state=42)\n...     X_train, X_test, y_train, y_test = splits\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(y_train.isin([0, 1])), 'y_train has values that are not 0 or 1.'\n...     assert np.all(y_test.isin([0, 1])), 'y_test has values that are not 0 or 1.'\n>>> test_correct_X()\n>>> test_correct_y()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_train_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     X_train, X_test, y_train, y_test = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     model = train_model(X_train, y_train)\n...     return isinstance(model, LogisticRegression)\n>>> test_train_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_evaluate_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     X_train, X_test, y_train, y_test = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     model = train_model(X_train, y_train)\n...     model = train_model(X_train, y_train)\n...     accuracy = evaluate_model(model, X_test, y_test)\n...     return bool(np.isclose(accuracy, 0.85, atol=0.1))\n>>> test_evaluate_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
