{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Introduction to Pandas and Scikit-Learn\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python. It provides data structures like DataFrames and Series that allow for efficient handling of structured data. Pandas is particularly useful for tasks such as reading and writing data in various formats, data cleaning, merging datasets, and performing complex operations on data.\n",
    "\n",
    "Scikit-learn, on the other hand, is a machine learning library for Python. It provides a wide range of supervised and unsupervised learning algorithms, as well as tools for model selection, evaluation, and preprocessing. Scikit-learn is designed to be user-friendly and efficient, making it a popular choice for both beginners and experienced data scientists.\n",
    "\n",
    "Together, Pandas and Scikit-learn form a powerful combination for data analysis and machine learning tasks. Pandas is often used to prepare and manipulate data, which can then be fed into Scikit-learn models for training and prediction.\n",
    "\n",
    "In this assignment, we'll start with the fundamentals of data loading/manipulation in pandas, then move on to basics of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick look at the dataset. We'll use the .head() function to view the first 5 records of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Feel free to refer to the course notes on [pandas](https://tools4ds.github.io/DS701-Course-Notes/02B-Pandas.html) for the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1a**: Write a function `get_rows_and_columns` that takes as input a CSV filename, loads this file into a Pandas dataframe, and returns a tuple of the number of rows and columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 1b**: Write a function `compute_missing_percentage` that converts '?' to NaN and returns the percentage of missing data (i.e., NaNs) for each column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1c**: Write a function `unique_ms` that returns the number of unique marital-statuses present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1d**: Write a function `get_categorical_columns` that identifies and returns a list of all the **categorical** columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 2: Exploratory data analysis and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2a**: Write a function `plot_categorical_distribution` to plot the distribution of the column 'relationship'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2b**: Write a function `plot_age_hours_scatter` that creates a scatter plot of 'age' vs 'hours-per-week', coloring points by 'income'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2c**: Write a function `plot_income_by_education` which plots a stacked bar chart that shows the proportion of income levels for each 'education' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Part 3: Advanced Pandas Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3a**: Write a function `education_stats` that returns a dataframe with mean 'age' and median 'hours-per-week' categorized on the 'education' level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3b**: Write a function `calculate_high_income_percentage` that returns a dataframe of the percentage of individuals earning >50K for each 'native-country' and order them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3c**: Write a function `occupations_by_hours` that returns a dataframe of the top 5 occupations with the highest average 'hours-per-week'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO RUN THIS CELL!\n",
    "\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "df_new = df.drop(columns=['native-country', 'fnlwgt']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll implement [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) using scikit-learn. Logistic regression is used when trying to predict a binary outcome (0 or 1, True or False, etc.) We will go over the details of logistic regression in details later in the course. \n",
    "\n",
    "Here, we will try to predict income (>50k or <= 50k>) and follow standard ML procedures for data pre-processing. You can use scikit-learn's documentation, [the lecture notes on scikit-learn](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html) or online resources for guidance. \n",
    "\n",
    "#### From here on use the 'df_new' variable instead of 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We saw in lecture that models are trained on the 'training' set and evaluated on unseen data on the 'testing' set. The dataset has 'feature' (`X_train`, `X_test`) and the 'outcome' (`y_train`, `y_test`) variables. \n",
    "\n",
    "**Question 4a:** Write a function called `split_data` that takes a dataframe as its only parameter, splits it into training and test splits and returns them. Use 20% for the testing set. \n",
    "\n",
    "Use `train_test_split` to produce the splits. Provide a `random_state` of 42 for reproducibility.\n",
    "\n",
    "`split_data` should return 4 things: X_train, X_test y_train and y_test. To do that, you need to pass in the X *and* the y (income column) to `train_test_split`.\n",
    "\n",
    "The feature columns that appear in X_train and X_test are the Dataframe columns that are NOT income. The target variables y_train and y_test are based on the income column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 4b**: Write a function `preprocess_data` that takes X_train, y_train, X_test, and y_test as input (the splits we created earlier!) and does the following:\n",
    "\n",
    " - Scale the *numerical* columns using sklearn's StandardScaler for both train and test sets\n",
    "  \n",
    " - Replace \"<=50K\" with 0 and \">50K\" with 1 in both y_train and y_test\n",
    "\n",
    " - One-hot encode the categorical columns for both train and test sets. Check the next cell for some hints! \n",
    "  \n",
    "The function should then return the preprocessed X_train, y_train, X_test, and y_test\n",
    "\n",
    "Refer to the material below and [sklearn course notes](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html#prepare-the-dataset) for help! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One hot encoding is a way of turning textual data into numbers, so that models can work with them. \n",
    "\n",
    "Pandas has a method called `pd.get_dummies()` that can do one-hot encoding. Here's an example usage: \n",
    "  \n",
    "   ```python\n",
    "    # Sample DataFrame with categorical columns\n",
    "    data = {'City': ['New York', 'Los Angeles', 'New York', 'Chicago'],\n",
    "        'Gender': ['Female', 'Male', 'Male', 'Female']}\n",
    "\n",
    "    df = pd.DataFrame(data) \n",
    "\n",
    "    df_encoded = pd.get_dummies(df, columns=['City', 'Gender']) # notice how I'm passing in the columns -- you should do this too! Hint: you wrote a function for this earlier. \n",
    "   ```\n",
    "   \n",
    "   And then `df_encoded` will look like: \n",
    "\n",
    "   ```python\n",
    "      City_Chicago  City_Los Angeles  City_New York  Gender_Female  Gender_Male\n",
    "    0             0                 0              1              1            0\n",
    "    1             0                 1              0              0            1\n",
    "    2             0                 0              1              0            1\n",
    "    3             1                 0              0              1            0\n",
    "   ```\n",
    "\n",
    "   Notice how now every `City` value has its own column, and that every row with a city has a 1 for that city (row 1 in the old dataframe has New York for the `City`, and row in the new dataframe has a 1 for `City_New York`). Everywhere else you have a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's get to training! Remember, we're trying to predict whether income is more then 50k (>50k), or less than or equal to (<=50k).\n",
    "\n",
    "**Question 4c:** Write a function called train_model that takes the training splits (X_train and y_train) as its parameters. \n",
    "\n",
    "- Initialize the logistic regression model\n",
    "- Fit it to our data. (Training step)\n",
    "\n",
    "At the end, return the fitted model. \n",
    "\n",
    "You can refer to [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's evaluate the performance of our model! \n",
    "\n",
    "**Question 4d:** Write a function called evaluate_model that takes the fitted model and `X_test`, `y_test` as parameters, runs the model on the testing features (`X_test`) and returns the *accuracy score* of the predictions against the ground truth (`y_test`). \n",
    "\n",
    "You can refer to [sklearn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Upload the completed notebook to Gradescope for viewing your result!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> get_rows_and_columns('adult.csv') == (48842, 15)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> get_rows_and_columns('adult.csv') == (4, 15)\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> unique_ms(df) == 7\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_ms(df) == 6\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> get_categorical_columns(df) == ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> get_categorical_columns(df) == ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(education_stats(df)) == 16\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(education_stats(df).columns) == {'education', 'age', 'hours-per-week'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(education_stats(df).iloc[0]['age'], 37.902808))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(education_stats(df).iloc[1]['hours-per-week'] == 40.0)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> int(education_stats(df)['hours-per-week'].value_counts().get(40.0, 0)) == 14\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> education_stats(df).iloc[13]['education'] == 'Preschool'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> education_stats(df).iloc[7]['education'] == 'Assoc-acdm'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(calculate_high_income_percentage(df)['France'], 42.10526315789473))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(calculate_high_income_percentage(df)['India'], 41.059603))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(calculate_high_income_percentage(df)['China'], 29.508197))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(top_5_occupations_by_hours(df)['Farming-fishing'], 46.81744966442953))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(top_5_occupations_by_hours(df)['Exec-managerial'], 44.975353))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(top_5_occupations_by_hours(df)['Prof-specialty'], 42))\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> \n>>> def test_split_data():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     output = split_data(df_new)\n...     assert len(output) == 4, 'split_data() should return 4 things. Make sure you pass both the X and the y to train_test_split.'\n...     X_train, X_test, y_train, y_test = output\n...     assert len(X_train) + len(X_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert len(y_train) + len(y_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert np.all(X_train.columns == X_test.columns), 'The columns in X_train and X_test are not the same.'\n...     assert len(X_train) > 0 and len(X_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n...     assert len(y_train) > 0 and len(y_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n>>> test_split_data()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> \n>>> def test_correct_X():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     X = df_new.drop(columns='income')\n...     y = df_new['income']\n...     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n...     categorical_columns = X_train.select_dtypes(include=['object']).columns\n...     scaler = StandardScaler()\n...     numerical_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n...     X_train_scaled = X_train.copy()\n...     X_test_scaled = X_test.copy()\n...     X_train_scaled[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n...     X_test_scaled[numerical_columns] = scaler.transform(X_test[numerical_columns])\n...     X_train_correct = pd.get_dummies(X_train_scaled, columns=categorical_columns)\n...     X_test_correct = pd.get_dummies(X_test_scaled, columns=categorical_columns)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         y_train = y_train.replace({'<=50K': 0, '>50K': 1})\n...         y_test = y_test.replace({'<=50K': 0, '>50K': 1})\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(X_train.columns == X_train_correct.columns), 'Columns in X_train are not correct.'\n...     assert np.all(X_test.columns == X_test_correct.columns), 'Columns in X_test are not correct.'\n...     assert np.all(X_train == X_train_correct), 'X_train is not correct.'\n...     assert np.all(X_test == X_test_correct), 'X_test is not correct.'\n>>> \n>>> def test_correct_y():\n...     splits = train_test_split(df_new, df_new.drop(columns='income'), test_size=0.2, random_state=42)\n...     X_train, X_test, y_train, y_test = splits\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         y_train_correct = y_train.replace({'<=50K': 0, '>50K': 1})\n...         y_test_correct = y_test.replace({'<=50K': 0, '>50K': 1})\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(y_train == y_train_correct), 'y_train is not correct.'\n...     assert np.all(y_test == y_test_correct), 'y_test is not correct.'\n>>> test_correct_X()\n>>> test_correct_y()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> \n>>> def test_train_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     X_train, X_test, y_train, y_test = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     model = train_model(X_train, y_train)\n...     return isinstance(model, LogisticRegression)\n>>> test_train_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> \n>>> def test_evaluate_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     X_train, X_test, y_train, y_test = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n...     model = train_model(X_train, y_train)\n...     model = train_model(X_train, y_train)\n...     accuracy = evaluate_model(model, X_test, y_test)\n...     return bool(np.isclose(accuracy, 0.85, atol=0.1))\n>>> test_evaluate_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
